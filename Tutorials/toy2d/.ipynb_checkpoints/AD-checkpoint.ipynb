{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29406def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import pprint\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from bnaf import *\n",
    "from tqdm import trange\n",
    "from data.generate2d import sample2d, energy2d\n",
    "\n",
    "# standard imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import make_moons\n",
    "# from generate2d import sample2d, energy2d\n",
    "\n",
    "# FrEIA imports\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "\n",
    "from nflows.distributions import normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7698845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5868, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.4247, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.4247, grad_fn=<MeanBackward0>)\n",
      "0 tensor(0.3183, grad_fn=<DivBackward0>)\n",
      "tensor(0.6718, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.5097, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.5097, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7935, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.6314, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.6314, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9576, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.7955, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.7955, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1369, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9748, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9748, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2671, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.1050, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.1050, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2893, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.1272, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.1272, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2881, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.1260, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.1260, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2451, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0830, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0830, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2094, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0473, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0473, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1741, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0120, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0120, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1313, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9692, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9692, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1174, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9553, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9553, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0890, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9269, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9269, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0780, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9159, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9159, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1172, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9551, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9551, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1207, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9586, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9586, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1484, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9863, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9863, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1791, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0170, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0170, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2013, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0391, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0391, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2036, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0414, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0414, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1917, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0296, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0296, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1598, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9977, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9977, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1320, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9699, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9699, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1312, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9691, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9691, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1273, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9652, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9652, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1296, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9675, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9675, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1612, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9991, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9991, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1708, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0087, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0087, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1792, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0171, grad_fn=<MeanBackward0>)\n",
      "tensor(-3.0171, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1541, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9919, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9919, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1154, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9533, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9533, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0868, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9247, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9247, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0789, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9168, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9168, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0677, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9055, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9055, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0539, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8918, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8918, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0948, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9327, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9327, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0787, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9166, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9166, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0698, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9077, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9077, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0634, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9013, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9013, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1112, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9490, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9490, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1087, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9466, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9466, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1182, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9561, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9561, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1456, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9835, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9835, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0747, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9126, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9126, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0536, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8915, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8915, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0423, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8802, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8802, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0515, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8894, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8894, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1122, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9500, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9500, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0379, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8758, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8758, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0120, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8499, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8499, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0153, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8532, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8532, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0282, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8660, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8660, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0817, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9196, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9196, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0937, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9316, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9316, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0762, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9140, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9140, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0629, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9008, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9008, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0185, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8564, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8564, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9741, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8120, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8120, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0190, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8569, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8569, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1218, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9597, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9597, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1106, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9485, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9485, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0747, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9125, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9125, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0455, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8834, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8834, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0124, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8503, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8503, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9460, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.7839, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.7839, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9733, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8111, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8111, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0777, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9156, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9156, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1029, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9408, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.9408, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0470, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8849, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8849, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9854, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8232, grad_fn=<MeanBackward0>)\n",
      "tensor(-2.8232, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-02c57e1eb115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN_DIM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# backpropagate and update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/flows/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/flows/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCHSIZE = 1000\n",
    "N_DIM = 2\n",
    "\n",
    "# we define a subnet for use inside an affine coupling block\n",
    "# for more detailed information see the full tutorial\n",
    "def subnet_fc(dims_in, dims_out):\n",
    "    return nn.Sequential(nn.Linear(dims_in, 512), nn.ReLU(),\n",
    "                         nn.Linear(512,  dims_out))\n",
    "\n",
    "# a simple chain of operations is collected by ReversibleSequential\n",
    "inn = Ff.SequenceINN(N_DIM)\n",
    "for k in range(8):\n",
    "    inn.append(Fm.AllInOneBlock, subnet_constructor=subnet_fc, permute_soft=True)\n",
    "\n",
    "inn.to(device)\n",
    "optimizer = torch.optim.Adam(inn.parameters(), lr=0.001)\n",
    "\n",
    "# a very basic training loop\n",
    "for i in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    # sample data from the moons distribution\n",
    "    data, label = make_moons(n_samples=BATCHSIZE, noise=0.05)\n",
    "    x = torch.Tensor(data).to(device)\n",
    "    # pass to INN and get transformed variable z and log Jacobian determinant\n",
    "    z, log_jac_det = inn(x)\n",
    "    \n",
    "#     print(z.size())\n",
    "#     plt.figure()\n",
    "#     plt.plot(z.detach().numpy()[:,0], z.detach().numpy()[:,1],'r.')\n",
    "#     plt.plot(x.detach().numpy()[:,0], x.detach().numpy()[:,1],'b.')\n",
    "    \n",
    "    # calculate the negative log-likelihood of the model with a standard normal prior\n",
    "#     loss = 0.5*torch.sum(z**2, 1) - log_jac_det\n",
    "    \n",
    "#     tt1 = 0.5*torch.sum(z**2, 1)\n",
    "#     tt2 = torch.distributions.Normal(torch.zeros_like(z), torch.ones_like(z)).log_prob(z).sum(-1)\n",
    "    shape = z.shape[1:]\n",
    "    log_z = normal.StandardNormal(shape=shape).log_prob(z)\n",
    "    \n",
    "#     print(tt1.mean())\n",
    "#     print(tt2.mean())\n",
    "#     print(tt3.mean())\n",
    "    \n",
    "    loss = log_z + log_jac_det\n",
    "    loss = -loss.mean() / N_DIM\n",
    "    # backpropagate and update the weights\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 100==0:\n",
    "        print(i,loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(z.detach().numpy()[:,0], z.detach().numpy()[:,1],'r.')\n",
    "plt.plot(x.detach().numpy()[:,0], x.detach().numpy()[:,1],'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41867389",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = make_moons(n_samples=1000, noise=0.05)\n",
    "plt.figure()\n",
    "plt.plot(data[:,0], data[:,1],'.')\n",
    "\n",
    "\n",
    "# sample from the INN by sampling from a standard normal and transforming\n",
    "# it in the reverse direction\n",
    "nsam = 1000\n",
    "zzz = torch.randn(nsam, N_DIM)\n",
    "samples0, _ = inn(zzz, rev=True)\n",
    "\n",
    "samples = samples0.detach().numpy()\n",
    "plt.figure()\n",
    "plt.plot(samples[:,0], samples[:,1],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54891b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
